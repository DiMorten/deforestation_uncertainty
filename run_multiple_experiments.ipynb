{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbd5b7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tracemalloc\n",
    "\n",
    "from utils_v1 import *\n",
    "import traceback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "123e793c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow ver. 2.6.0\n"
     ]
    }
   ],
   "source": [
    "from icecream import ic\n",
    "\n",
    "import numpy as np\n",
    "from src.dataset import (\n",
    "    MultipleDates, PAMultipleDates,\n",
    "    MTMultipleDates, MSMultipleDates, PIMultipleDates\n",
    ")\n",
    "\n",
    "# from src.dataset_legacy import MTDeforestationTime\n",
    "from src import training_generator as generator\n",
    "from src.patchesHandler import PatchesHandler, PatchesHandlerMultipleDates, PatchesHandlerEvidential2\n",
    "\n",
    "from src.manager.evidential import ManagerEvidential\n",
    "from src.manager.multioutput import ManagerMCDropout, ManagerSingleRun, ManagerEvidential2\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import cv2\n",
    "from src import metrics as _metric\n",
    "import json\n",
    "import pickle \n",
    "import src.manager.evidential as evidential\n",
    "from src.Logger import Logger\n",
    "import pdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7a6829f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: evidential2. Site: PA. Training: True. Training date: current\n",
      "{'training': True, 'inferring': True, 'site': 'PA', 'training_date': 'current', 'mode': 'evidential2', 'training_times': 1, 'uncertainty_method': 'pred_entropy', 'loadInference': False, 'removePolygons': True, 'plotLandsat': False, 'plotPOI': False, 'save_probabilities': False, 'addPastDeforestationInput': True, 'classes_mode': True, 'learning_rate': 0.0001, 'use_cloud_mask': True}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('config/config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "    \n",
    "print(\"Mode: {}. Site: {}. Training: {}. Training date: {}\".format(\n",
    "    config['mode'], config['site'], config['training'], config['training_date']))\n",
    "print(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "603a5df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| list(self.date_ids): [0]\n",
      "ic| self.image_channels: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]]\n",
      "ic| dates: [2018, 2019]\n",
      "ic| self.input_image_shape: 21\n",
      "ic| self.dataset.image_channels: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if config['site'] == 'PA':\n",
    "\tif config['training_date'] == 'earlier':\n",
    "\t\tdates = [2017, 2018]\n",
    "\telse:\n",
    "\t\tdates = [2018, 2019]\n",
    "\tdatasetClass = PAMultipleDates\n",
    "elif config['site'] == 'MT':\n",
    "\tif config['training_date'] == 'earlier':\n",
    "\t\tdates = [2018, 2019]\n",
    "\telse:\n",
    "\t\tdates = [2019, 2020]\n",
    "\tdatasetClass = MTMultipleDates\n",
    "elif config['site'] == 'MS':\n",
    "\tif config['training_date'] == 'earlier':\n",
    "\t\tdates = [2018, 2019]\n",
    "\telse:\n",
    "\t\tdates = [2019, 2020]\n",
    "\tdatasetClass = MSMultipleDates\n",
    "elif config['site'] == 'PI':\n",
    "\tif config['training_date'] == 'earlier':\n",
    "\t\tdates = [2018, 2019]\n",
    "\telse:\n",
    "\t\tdates = [2019, 2020]\n",
    "\tdatasetClass = PIMultipleDates\n",
    "else:\n",
    "\traise ValueError('Invalid site')\n",
    "\n",
    "dataset = datasetClass(config = config,\n",
    "\t\t\t   dates = dates, \n",
    "\t \taddPastDeforestationInput = config['addPastDeforestationInput'],\n",
    "\t\tborderBuffer = 2)\t\n",
    "\n",
    "if config['mode'] == 'ensemble':\n",
    "\tif config['training'] == True:\n",
    "\t\tconfig['mode'] = 'single_run'\n",
    "\telse:\n",
    "\t\tsys.exit(\"Ensure that training is True for ensemble mode. Use infer_ensemble.ipynb for inference.\")\n",
    "\n",
    "if config['training'] == False:\n",
    "\tif config['site'] == 'PA':\n",
    "\t\tif config['mode'] == 'mcd' or config['mode'] == 'single_run': # MCD will do 10 inference on each of the 10 repetitions = 100 runs\n",
    "\t\t\tif config['training_date'] == 'current': exp = 0\n",
    "\t\t\telif config['training_date'] == 'earlier': exp = 1\n",
    "\t\t\t\t\n",
    "\t\tif config['mode'] == 'evidential2':\n",
    "\t\t\tif config['training_date'] == 'current': exp = 8; repetition_id = 0\n",
    "\t\t\telif config['training_date'] == 'earlier': exp = 9; repetition_id = 0\n",
    "\n",
    "\telse:\n",
    "\n",
    "\t\tif config['mode'] == 'mcd' or config['mode'] == 'single_run':\n",
    "\t\t\tif config['training_date'] == 'current': exp = 2\n",
    "\t\t\telif config['training_date'] == 'earlier': exp = 3\n",
    "\t\tif config['mode'] == 'evidential2':\n",
    "\t\t\tif config['training_date'] == 'current': exp = 10; repetition_id = 0\n",
    "\t\t\telif config['training_date'] == 'earlier': exp = 11; repetition_id = 0\n",
    "\n",
    "else:\n",
    "\texp = 8\n",
    "ic(dates)\n",
    "\n",
    "\n",
    "if issubclass(type(dataset), MultipleDates):\n",
    "\tpatchesHandler = PatchesHandlerMultipleDates(\n",
    "\t\tdataset)\n",
    "elif config['mode'] == 'evidential2':\n",
    "\tpatchesHandler = PatchesHandlerEvidential2()\n",
    "else:\n",
    "\tpatchesHandler = PatchesHandler()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bb339c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if config['mode'] == 'evidential2':\n",
    "    config[\"inference_times\"] = 1\n",
    "    manager_class = ManagerEvidential2\n",
    "    config['uncertainty_method'] = \"pred_entropy\"\n",
    "    config['classes_mode'] = True\n",
    "    \n",
    "if config['mode'] == 'mcd':\n",
    "    config[\"inference_times\"] = 10\n",
    "    manager_class = ManagerMCDropout\n",
    "    config['uncertainty_method'] = \"pred_entropy\"\n",
    "    config['classes_mode'] = False\n",
    "\n",
    "elif config['mode'] == 'single_run':\n",
    "    config[\"inference_times\"] = 1\n",
    "    manager_class = ManagerSingleRun\n",
    "    config['uncertainty_method'] = \"pred_entropy_single\"\n",
    "    config['classes_mode'] = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7ae3a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfa1145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = Logger()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55da0bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manager.config['dropout_training'] False\n",
      "D:/Jorge/datasets/deforestation/PA/deforestation_past_years.tif\n",
      "Loaded deforestation past years\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| np.unique(deforestation_past_years, return_counts=True): (array([   0, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017,\n",
      "                                                                    2018, 2019, 2020, 2021], dtype=uint16),\n",
      "                                                              array([132185553,   3150503,   4571354,    864429,    903608,   1299506,\n",
      "                                                                      2477971,   1561686,   1459696,    969060,    644976,   2209014,\n",
      "                                                                      2100204,   5257014,   3514616], dtype=int64))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label where deforestation past years is actual date (2019) = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| np.unique(deforestation_past_years, return_counts=True): (array([   0, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017,\n",
      "                                                                    2018, 2019, 2020, 2021], dtype=uint16),\n",
      "                                                              array([132185553,   3150503,   4571354,    864429,    903608,   1299506,\n",
      "                                                                      2477971,   1561686,   1459696,    969060,    644976,   2209014,\n",
      "                                                                      2100204,   5257014,   3514616], dtype=int64))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Past deforestation different from 0 (no deforestation)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| np.unique(deforestation_past_years, return_counts=True): (array([   0, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017,\n",
      "                                                                    2018, 2019, 2020, 2021], dtype=uint16),\n",
      "                                                              array([132185553,   3150503,   4571354,    864429,    903608,   1299506,\n",
      "                                                                      2477971,   1561686,   1459696,    969060,    644976,   2209014,\n",
      "                                                                      2100204,   5257014,   3514616], dtype=int64))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Past deforestation before 2008 is 2\n",
      "D:/Jorge/datasets/deforestation/PA/deforestation_before_2008_PA.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| np.unique(label_past_deforestation_before_2008, return_counts=True): (array([  0, 215], dtype=uint8), array([124211220,  38957970], dtype=int64))\n",
      "ic| np.unique(deforestation_past_years, return_counts=True): (array([   0, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017,\n",
      "                                                                    2018, 2019, 2020, 2021], dtype=uint16),\n",
      "                                                              array([132185553,   3150503,   4571354,    864429,    903608,   1299506,\n",
      "                                                                      2477971,   1561686,   1459696,    969060,    644976,   2209014,\n",
      "                                                                      2100204,   5257014,   3514616], dtype=int64))\n",
      "ic| label_per_date.shape: (17730, 9203, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing bufer................\n",
      "Mask label shape:  \n",
      " (17730, 9203, 1) \n",
      " Unique values:  \n",
      " [0 1 2]\n",
      "Tiles size:  3546 2300\n",
      "Mask size:  (17730, 9200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| image_stack.shape: (17730, 9203, 21)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape:  (17730, 9203, 21)\n",
      "mask:  (17730, 9200)\n",
      "image stack:  (17730, 9200, 21)\n",
      "ref : (17730, 9200, 1)\n",
      "Training tiles:  [1, 3, 5, 8, 11, 13, 14, 20]\n",
      "Validation tiles:  [6, 19]\n",
      "Test tiles:  [2, 4, 7, 9, 10, 12, 15, 16, 17, 18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| im_idx_row.shape: (17730, 9200, 1)\n",
      "    im_idx_col.shape: (17730, 9200, 1)\n",
      "ic| im_idx_row.dtype: dtype('uint16')\n",
      "    im_idx_col.dtype: dtype('uint16')\n",
      "ic| im_idx.shape: (17730, 9200, 2), im_idx.dtype: dtype('uint16')\n",
      "ic| coords.shape: (464, 239, 1, 128, 128, 2)\n",
      "    coords.dtype: dtype('uint16')\n",
      "ic| coords.shape: (110896, 2), coords.dtype: dtype('uint16')\n",
      "ic| self.coords_train.shape: (41812, 3)\n",
      "    self.coords_val.shape: (10260, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training samples:  (3753, 3) validation samples:  (1032, 3)\n",
      "time:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jchamorro\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_enc_net (InputLayer)      [(None, 128, 128, 21 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "res1_net1 (Conv2D)              (None, 128, 128, 16) 3040        input_enc_net[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "drop_net1 (SpatialDropout2D)    (None, 128, 128, 16) 0           res1_net1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2_net1 (Conv2D)              (None, 128, 128, 16) 2320        drop_net1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res3_net1 (Conv2D)              (None, 128, 128, 16) 352         input_enc_net[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 128, 128, 16) 0           res2_net1[0][0]                  \n",
      "                                                                 res3_net1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool_net1 (MaxPooling2D)        (None, 64, 64, 16)   0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "res1_net2 (Conv2D)              (None, 64, 64, 32)   4640        pool_net1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "drop_net2 (SpatialDropout2D)    (None, 64, 64, 32)   0           res1_net2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2_net2 (Conv2D)              (None, 64, 64, 32)   9248        drop_net2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res3_net2 (Conv2D)              (None, 64, 64, 32)   544         pool_net1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 64, 32)   0           res2_net2[0][0]                  \n",
      "                                                                 res3_net2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool_net2 (MaxPooling2D)        (None, 32, 32, 32)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res1_net3 (Conv2D)              (None, 32, 32, 64)   18496       pool_net2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "drop_net3 (SpatialDropout2D)    (None, 32, 32, 64)   0           res1_net3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2_net3 (Conv2D)              (None, 32, 32, 64)   36928       drop_net3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res3_net3 (Conv2D)              (None, 32, 32, 64)   2112        pool_net2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 64)   0           res2_net3[0][0]                  \n",
      "                                                                 res3_net3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool_net3 (MaxPooling2D)        (None, 16, 16, 64)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res1_net4 (Conv2D)              (None, 16, 16, 64)   36928       pool_net3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "drop_net4 (SpatialDropout2D)    (None, 16, 16, 64)   0           res1_net4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2_net4 (Conv2D)              (None, 16, 16, 64)   36928       drop_net4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res3_net4 (Conv2D)              (None, 16, 16, 64)   4160        pool_net3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 16, 16, 64)   0           res2_net4[0][0]                  \n",
      "                                                                 res3_net4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res1_net5 (Conv2D)              (None, 16, 16, 64)   36928       add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "drop_net5 (SpatialDropout2D)    (None, 16, 16, 64)   0           res1_net5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2_net5 (Conv2D)              (None, 16, 16, 64)   36928       drop_net5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res3_net5 (Conv2D)              (None, 16, 16, 64)   4160        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 64)   0           res2_net5[0][0]                  \n",
      "                                                                 res3_net5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res1_net6 (Conv2D)              (None, 16, 16, 64)   36928       add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "drop_net6 (SpatialDropout2D)    (None, 16, 16, 64)   0           res1_net6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2_net6 (Conv2D)              (None, 16, 16, 64)   36928       drop_net6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res3_net6 (Conv2D)              (None, 16, 16, 64)   4160        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 64)   0           res2_net6[0][0]                  \n",
      "                                                                 res3_net6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 32, 32, 64)   0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "upsampling_net3 (Conv2D)        (None, 32, 32, 64)   36928       up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d (SpatialDropo (None, 32, 32, 64)   0           upsampling_net3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate3 (Concatenate)      (None, 32, 32, 128)  0           add_2[0][0]                      \n",
      "                                                                 spatial_dropout2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 128)  0           concatenate3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "upsampling_net2 (Conv2D)        (None, 64, 64, 32)   36896       up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_1 (SpatialDro (None, 64, 64, 32)   0           upsampling_net2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate2 (Concatenate)      (None, 64, 64, 64)   0           add_1[0][0]                      \n",
      "                                                                 spatial_dropout2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 64) 0           concatenate2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "upsampling_net1 (Conv2D)        (None, 128, 128, 16) 9232        up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_2 (SpatialDro (None, 128, 128, 16) 0           upsampling_net1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate1 (Concatenate)      (None, 128, 128, 32) 0           add[0][0]                        \n",
      "                                                                 spatial_dropout2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "output (Conv2D)                 (None, 128, 128, 2)  66          concatenate1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dirichlet_layer (DirichletLayer (None, 128, 128, 2)  0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 394,850\n",
      "Trainable params: 394,850\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch: 1\n",
      "Anneling Coeficient 0\n",
      "K.int_shape(mse) (None, 128, 128, 1)\n",
      "K.int_shape(mask) (None, None, None, 1)\n",
      "K.int_shape(E) (None, 128, 128, 2)\n",
      "K.int_shape(y_truth) (None, None, None, None)\n",
      "K.int_shape(mse) (None, 128, 128, 1)\n",
      "K.int_shape(mask) (None, None, None, 1)\n",
      "K.int_shape(E) (None, 128, 128, 2)\n",
      "K.int_shape(y_truth) (None, None, None, None)\n",
      "351/351 [==============================] - ETA: 0s - loss: 0.3360 - accuracy: 0.4560K.int_shape(mse) (None, 128, 128, 1)\n",
      "K.int_shape(mask) (None, None, None, 1)\n",
      "K.int_shape(E) (None, 128, 128, 2)\n",
      "K.int_shape(y_truth) (None, None, None, None)\n",
      "351/351 [==============================] - 38s 93ms/step - loss: 0.3360 - accuracy: 0.4560 - val_loss: 0.3072 - val_accuracy: 0.5169\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.30724, saving model to D:/Jorge/datasets/deforestation/experiments/PA/exp8/models\\resunet_0.h5\n",
      "New best val loss. Val loss: 0.30724. Early stop count: 0\n",
      "Epoch: 2\n",
      "Anneling Coeficient [0.1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jchamorro\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 32s 91ms/step - loss: 0.2679 - accuracy: 0.4556 - val_loss: 0.2703 - val_accuracy: 0.5151\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.30724 to 0.27027, saving model to D:/Jorge/datasets/deforestation/experiments/PA/exp8/models\\resunet_0.h5\n",
      "New best val loss. Val loss: 0.27027. Early stop count: 0\n",
      "Epoch: 3\n",
      "Anneling Coeficient [0.2]\n",
      "351/351 [==============================] - 32s 91ms/step - loss: 0.2561 - accuracy: 0.4560 - val_loss: 0.2684 - val_accuracy: 0.5107\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.27027 to 0.26841, saving model to D:/Jorge/datasets/deforestation/experiments/PA/exp8/models\\resunet_0.h5\n",
      "New best val loss. Val loss: 0.26841. Early stop count: 0\n",
      "Epoch: 4\n",
      "Anneling Coeficient [0.3]\n",
      "351/351 [==============================] - 32s 90ms/step - loss: 0.2517 - accuracy: 0.4558 - val_loss: 0.2658 - val_accuracy: 0.5111\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.26841 to 0.26584, saving model to D:/Jorge/datasets/deforestation/experiments/PA/exp8/models\\resunet_0.h5\n",
      "New best val loss. Val loss: 0.26584. Early stop count: 0\n",
      "Epoch: 5\n",
      "Anneling Coeficient [0.4]\n",
      "351/351 [==============================] - 32s 90ms/step - loss: 0.2498 - accuracy: 0.4559 - val_loss: 0.2627 - val_accuracy: 0.5208\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.26584 to 0.26267, saving model to D:/Jorge/datasets/deforestation/experiments/PA/exp8/models\\resunet_0.h5\n",
      "New best val loss. Val loss: 0.26267. Early stop count: 0\n",
      "Epoch: 6\n",
      "Anneling Coeficient [0.5]\n",
      "351/351 [==============================] - 32s 90ms/step - loss: 0.2475 - accuracy: 0.4558 - val_loss: 0.2609 - val_accuracy: 0.5170\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.26267 to 0.26088, saving model to D:/Jorge/datasets/deforestation/experiments/PA/exp8/models\\resunet_0.h5\n",
      "New best val loss. Val loss: 0.26088. Early stop count: 0\n",
      "Epoch: 7\n",
      "Anneling Coeficient [0.6]\n",
      "351/351 [==============================] - 32s 90ms/step - loss: 0.2457 - accuracy: 0.4687 - val_loss: 0.2532 - val_accuracy: 0.6095\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.26088 to 0.25320, saving model to D:/Jorge/datasets/deforestation/experiments/PA/exp8/models\\resunet_0.h5\n",
      "New best val loss. Val loss: 0.2532. Early stop count: 0\n",
      "Epoch: 8\n",
      "Anneling Coeficient [0.7]\n",
      "351/351 [==============================] - 32s 90ms/step - loss: 0.2373 - accuracy: 0.5299 - val_loss: 0.2505 - val_accuracy: 0.6287\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.25320 to 0.25049, saving model to D:/Jorge/datasets/deforestation/experiments/PA/exp8/models\\resunet_0.h5\n",
      "New best val loss. Val loss: 0.25049. Early stop count: 0\n",
      "Epoch: 9\n",
      "Anneling Coeficient [0.8]\n",
      "351/351 [==============================] - 32s 91ms/step - loss: 0.2344 - accuracy: 0.5415 - val_loss: 0.2474 - val_accuracy: 0.6350\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.25049 to 0.24735, saving model to D:/Jorge/datasets/deforestation/experiments/PA/exp8/models\\resunet_0.h5\n",
      "New best val loss. Val loss: 0.24735. Early stop count: 0\n",
      "Epoch: 10\n",
      "Anneling Coeficient [0.9]\n",
      "351/351 [==============================] - 32s 90ms/step - loss: 0.2311 - accuracy: 0.5482 - val_loss: 0.2550 - val_accuracy: 0.6387\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24735\n",
      "Early stop count: 1\n",
      "Epoch: 11\n",
      "Anneling Coeficient [1.]\n",
      "351/351 [==============================] - 31s 89ms/step - loss: 0.2298 - accuracy: 0.5488 - val_loss: 0.2495 - val_accuracy: 0.6432\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24735\n",
      "Early stop count: 2\n",
      "Epoch: 12\n",
      "Anneling Coeficient [1.]\n",
      "351/351 [==============================] - 30s 87ms/step - loss: 0.2273 - accuracy: 0.5499 - val_loss: 0.2479 - val_accuracy: 0.6515\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24735\n",
      "Early stop count: 3\n",
      "Epoch: 13\n",
      "Anneling Coeficient [1.]\n",
      "351/351 [==============================] - 31s 87ms/step - loss: 0.2266 - accuracy: 0.5529 - val_loss: 0.2454 - val_accuracy: 0.6477\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.24735 to 0.24537, saving model to D:/Jorge/datasets/deforestation/experiments/PA/exp8/models\\resunet_0.h5\n",
      "New best val loss. Val loss: 0.24537. Early stop count: 0\n",
      "Epoch: 14\n",
      "Anneling Coeficient [1.]\n",
      "351/351 [==============================] - 31s 88ms/step - loss: 0.2250 - accuracy: 0.5528 - val_loss: 0.2463 - val_accuracy: 0.6457\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24537\n",
      "Early stop count: 1\n",
      "Epoch: 15\n",
      "Anneling Coeficient [1.]\n",
      "351/351 [==============================] - 31s 88ms/step - loss: 0.2244 - accuracy: 0.5531 - val_loss: 0.2474 - val_accuracy: 0.6441\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24537\n",
      "Early stop count: 2\n",
      "Epoch: 16\n",
      "Anneling Coeficient [1.]\n",
      "351/351 [==============================] - 31s 88ms/step - loss: 0.2229 - accuracy: 0.5535 - val_loss: 0.2466 - val_accuracy: 0.6418\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24537\n",
      "Early stop count: 3\n",
      "Epoch: 17\n",
      "Anneling Coeficient [1.]\n",
      "351/351 [==============================] - 31s 87ms/step - loss: 0.2227 - accuracy: 0.5549 - val_loss: 0.2441 - val_accuracy: 0.6413\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.24537 to 0.24413, saving model to D:/Jorge/datasets/deforestation/experiments/PA/exp8/models\\resunet_0.h5\n",
      "New best val loss. Val loss: 0.24413. Early stop count: 0\n",
      "Epoch: 18\n",
      "Anneling Coeficient [1.]\n",
      "351/351 [==============================] - 31s 87ms/step - loss: 0.2209 - accuracy: 0.5533 - val_loss: 0.2402 - val_accuracy: 0.6462\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.24413 to 0.24024, saving model to D:/Jorge/datasets/deforestation/experiments/PA/exp8/models\\resunet_0.h5\n",
      "New best val loss. Val loss: 0.24024. Early stop count: 0\n",
      "Epoch: 19\n",
      "Anneling Coeficient [1.]\n",
      "351/351 [==============================] - 32s 92ms/step - loss: 0.2206 - accuracy: 0.5558 - val_loss: 0.2412 - val_accuracy: 0.6437\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24024\n",
      "Early stop count: 1\n",
      "Epoch: 20\n",
      "Anneling Coeficient [1.]\n",
      "351/351 [==============================] - 32s 90ms/step - loss: 0.2192 - accuracy: 0.5559 - val_loss: 0.2467 - val_accuracy: 0.6471\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24024\n",
      "Early stop count: 2\n",
      "Epoch: 21\n",
      "Anneling Coeficient [1.]\n",
      "351/351 [==============================] - 31s 90ms/step - loss: 0.2183 - accuracy: 0.5617 - val_loss: 0.2430 - val_accuracy: 0.6401\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24024\n",
      "Early stop count: 3\n",
      "Epoch: 22\n",
      "Anneling Coeficient [1.]\n",
      "351/351 [==============================] - 32s 90ms/step - loss: 0.2172 - accuracy: 0.5608 - val_loss: 0.2449 - val_accuracy: 0.6430\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24024\n",
      "Early stop count: 4\n",
      "Epoch: 23\n",
      "Anneling Coeficient [1.]\n",
      "351/351 [==============================] - 31s 90ms/step - loss: 0.2171 - accuracy: 0.5633 - val_loss: 0.2434 - val_accuracy: 0.6457\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24024\n",
      "Early stop count: 5\n",
      "Epoch: 24\n",
      "Anneling Coeficient [1.]\n",
      "351/351 [==============================] - 31s 89ms/step - loss: 0.2156 - accuracy: 0.5639 - val_loss: 0.2459 - val_accuracy: 0.6564\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24024\n",
      "Early stop count: 6\n",
      "Epoch: 25\n",
      "Anneling Coeficient [1.]\n",
      "351/351 [==============================] - 31s 89ms/step - loss: 0.2150 - accuracy: 0.5635 - val_loss: 0.2468 - val_accuracy: 0.6552\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24024\n",
      "Early stop count: 7\n",
      "Epoch: 26\n",
      "Anneling Coeficient [1.]\n",
      "351/351 [==============================] - 31s 88ms/step - loss: 0.2149 - accuracy: 0.5639 - val_loss: 0.2467 - val_accuracy: 0.6510\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24024\n",
      "Early stop count: 8\n",
      "Epoch: 27\n",
      "Anneling Coeficient [1.]\n",
      "351/351 [==============================] - 31s 89ms/step - loss: 0.2138 - accuracy: 0.5640 - val_loss: 0.2495 - val_accuracy: 0.6466\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24024\n",
      "Early stop count: 9\n",
      "Epoch: 28\n",
      "Anneling Coeficient [1.]\n",
      "351/351 [==============================] - 31s 89ms/step - loss: 0.2132 - accuracy: 0.5639 - val_loss: 0.2449 - val_accuracy: 0.6560\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.24024\n",
      "Early stop count: 10\n",
      "Early stopping\n",
      "10 10\n",
      "Finished Training\n",
      "Training time:  888.9047465324402\n"
     ]
    }
   ],
   "source": [
    "if config['training'] == True:\n",
    "    \n",
    "\n",
    "    manager = manager_class(config, dataset, patchesHandler, logger)\n",
    "    print(\"manager.config['dropout_training']\", manager.config['dropout_training'])\n",
    "    manager.defineExperiment(exp) # fixed\n",
    "    \n",
    "    manager.setExperimentPath()\n",
    "    manager.createLogFolders()\n",
    "\n",
    "    manager.loadDataset()\n",
    "\n",
    "    # %%\n",
    "    if config[\"training\"] == True:\n",
    "        manager.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a13e82bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| list(self.date_ids): [0]\n",
      "ic| self.image_channels: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]]\n",
      "ic| dates: [2018, 2019]\n",
      "ic| self.input_image_shape: 21\n",
      "ic| self.dataset.image_channels: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "if config['site'] == 'PA':\n",
    "\tdates = [2018, 2019]\n",
    "\tdatasetClass = PAMultipleDates\n",
    "elif config['site'] == 'MT':\n",
    "\tdates = [2019, 2020]\n",
    "\tdatasetClass = MTMultipleDates\n",
    "elif config['site'] == 'MS':\n",
    "\tdates = [2019, 2020]\n",
    "\tdatasetClass = MSMultipleDates\n",
    "elif config['site'] == 'PI':\n",
    "\tdates = [2019, 2020]\n",
    "\tdatasetClass = PIMultipleDates\n",
    "else:\n",
    "\traise ValueError('Invalid site')\n",
    "\n",
    "dataset = datasetClass(config = config,\n",
    "\t\t\t   dates = dates, \n",
    "\t \taddPastDeforestationInput = config['addPastDeforestationInput'],\n",
    "\t\tborderBuffer = 2)\n",
    "\n",
    "\n",
    "ic(dates)\n",
    "\n",
    "if issubclass(type(dataset), MultipleDates):\n",
    "\tpatchesHandler = PatchesHandlerMultipleDates(\n",
    "\t\tdataset)\n",
    "elif config['mode'] == 'evidential2':\n",
    "\tpatchesHandler = PatchesHandlerEvidential2()\n",
    "else:\n",
    "\tpatchesHandler = PatchesHandler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "597049da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "src.manager.multioutput.ManagerEvidential2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manager_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82354e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e69f832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repetition_ids [0], repetition_n 1\n"
     ]
    }
   ],
   "source": [
    "repetition_ids = manager_class(config, dataset, patchesHandler, logger).get_repetition_ids(exp)  \n",
    "repetition_n = len(repetition_ids)\n",
    "print(\"repetition_ids {}, repetition_n {}\".format(repetition_ids, repetition_n))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5997b986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning run number 0\n",
      "manager.config {'training': True, 'inferring': True, 'site': 'PA', 'training_date': 'current', 'mode': 'evidential2', 'training_times': 1, 'uncertainty_method': 'pred_entropy', 'loadInference': False, 'removePolygons': True, 'plotLandsat': False, 'plotPOI': False, 'save_probabilities': False, 'addPastDeforestationInput': True, 'classes_mode': True, 'learning_rate': 0.0001, 'use_cloud_mask': True, 'inference_times': 1, 'dropout_training': False}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/Jorge/datasets/deforestation/PA/deforestation_past_years.tif\n",
      "Loaded deforestation past years\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| np.unique(deforestation_past_years, return_counts=True): (array([   0, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017,\n",
      "                                                                    2018, 2019, 2020, 2021], dtype=uint16),\n",
      "                                                              array([132185553,   3150503,   4571354,    864429,    903608,   1299506,\n",
      "                                                                      2477971,   1561686,   1459696,    969060,    644976,   2209014,\n",
      "                                                                      2100204,   5257014,   3514616], dtype=int64))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label where deforestation past years is actual date (2019) = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| np.unique(deforestation_past_years, return_counts=True): (array([   0, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017,\n",
      "                                                                    2018, 2019, 2020, 2021], dtype=uint16),\n",
      "                                                              array([132185553,   3150503,   4571354,    864429,    903608,   1299506,\n",
      "                                                                      2477971,   1561686,   1459696,    969060,    644976,   2209014,\n",
      "                                                                      2100204,   5257014,   3514616], dtype=int64))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Past deforestation different from 0 (no deforestation)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| np.unique(deforestation_past_years, return_counts=True): (array([   0, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017,\n",
      "                                                                    2018, 2019, 2020, 2021], dtype=uint16),\n",
      "                                                              array([132185553,   3150503,   4571354,    864429,    903608,   1299506,\n",
      "                                                                      2477971,   1561686,   1459696,    969060,    644976,   2209014,\n",
      "                                                                      2100204,   5257014,   3514616], dtype=int64))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Past deforestation before 2008 is 2\n",
      "D:/Jorge/datasets/deforestation/PA/deforestation_before_2008_PA.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| np.unique(label_past_deforestation_before_2008, return_counts=True): (array([  0, 215], dtype=uint8), array([124211220,  38957970], dtype=int64))\n",
      "ic| np.unique(deforestation_past_years, return_counts=True): (array([   0, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017,\n",
      "                                                                    2018, 2019, 2020, 2021], dtype=uint16),\n",
      "                                                              array([132185553,   3150503,   4571354,    864429,    903608,   1299506,\n",
      "                                                                      2477971,   1561686,   1459696,    969060,    644976,   2209014,\n",
      "                                                                      2100204,   5257014,   3514616], dtype=int64))\n",
      "ic| label_per_date.shape: (17730, 9203, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing bufer................\n",
      "Mask label shape:  \n",
      " (17730, 9203, 1) \n",
      " Unique values:  \n",
      " [0 1 2]\n",
      "Tiles size:  3546 2300\n",
      "Mask size:  (17730, 9200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| image_stack.shape: (17730, 9203, 21)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape:  (17730, 9203, 21)\n",
      "mask:  (17730, 9200)\n",
      "image stack:  (17730, 9200, 21)\n",
      "ref : (17730, 9200, 1)\n",
      "Training tiles:  [1, 3, 5, 8, 11, 13, 14, 20]\n",
      "Validation tiles:  [6, 19]\n",
      "Test tiles:  [2, 4, 7, 9, 10, 12, 15, 16, 17, 18]\n",
      "-30.0 -16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| self.path_models+ '/' + self.method +'_'+str(self.repetition_id)+'.h5': 'D:/Jorge/datasets/deforestation/experiments/PA/exp8/models/resunet_0.h5'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropout training mode: False\n",
      "time:  0\n",
      "alpha.shape (17760, 9216, 2)\n",
      "S.shape (17760, 9216)\n",
      "K 2\n",
      "u.shape (17760, 9216)\n",
      "belief.shape (17760, 9216, 2)\n",
      "(54236371,)\n",
      "(array([0, 1], dtype=uint8), array([53470765,   765606], dtype=int64))\n",
      "(17730, 9200, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| predicted_test.shape: (81558000,)\n",
      "ic| predicted_test.shape: (54236371,)\n",
      "ic| np.unique(predicted, return_counts=True): (array([0, 1], dtype=int8), array([161226408,   1889592], dtype=int64))\n",
      "    np.unique(predicted_larger_than_min_area, return_counts=True): (array([0, 1], dtype=int8), array([161392713,   1723287], dtype=int64))\n",
      "ic| np.unique(ignored_polygons, return_counts=True): (array([0, 1], dtype=int8), array([162949695,    166305], dtype=int64))\n",
      "ic| self.f1: 80.31, self.precision: 82.81, self.recall: 77.95\n",
      "ic| self.label_mask_val.shape: (16311600,)\n",
      "ic| self.label_mask_val_valid.shape: (9433405,)\n",
      "ic| f1_val: 82.99\n",
      "    precision_val: 81.67\n",
      "    recall_val: 84.36\n",
      "    mAP_val: 82.64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1], dtype=int16), array([162386659,    729341], dtype=int64))\n",
      "[0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| self.label_mask.shape: (17730, 9200)\n",
      "ic| self.mask_amazon_ts.shape: (17730, 9200)\n",
      "ic| self.label_mask_test.shape: (81558000,)\n",
      "ic| self.error_mask_test.shape: (54151420,)\n",
      "ic| bounds: (0.0015907875000848435, 0.4985)\n",
      "c:\\Users\\jchamorro\\Anaconda3\\envs\\tf2\\lib\\site-packages\\scipy\\optimize\\_minimize.py:783: RuntimeWarning: Method 'bounded' does not support relative tolerance in x; defaulting to absolute tolerance.\n",
      "  warn(\"Method 'bounded' does not support relative tolerance in x; \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1913932173521083\n",
      "threshold 0.1913932173521083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| label_current_deforestation_test_classified_incorrect.shape: (3630715,)\n",
      "    predicted_test_classified_incorrect.shape: (3630715,)\n",
      "ic| TP_H + FN_H + FP_H + TN_H: 3630715\n",
      "    len(label_mask_current_deforestation_test): 54151420\n",
      "ic| TP_H + FN_H + FP_H + TN_H: 3630715\n",
      "    len(label_mask_current_deforestation_test): 54151420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92943309 0.96717995 0.49909935 0.06704746 0.6936035  0.57934403\n",
      " 0.06561017]\n",
      "0.3086975701479765\n",
      "threshold 0.3086975701479765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| label_current_deforestation_test_classified_incorrect.shape: (2443275,)\n",
      "    predicted_test_classified_incorrect.shape: (2443275,)\n",
      "ic| TP_H + FN_H + FP_H + TN_H: 2443275\n",
      "    len(label_mask_current_deforestation_test): 54151420\n",
      "ic| TP_H + FN_H + FP_H + TN_H: 2443275\n",
      "    len(label_mask_current_deforestation_test): 54151420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90761992 0.96038153 0.60501455 0.04511932 0.63526022 0.47149722\n",
      " 0.08677303]\n",
      "0.3811956472041318\n",
      "threshold 0.3811956472041318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| label_current_deforestation_test_classified_incorrect.shape: (1873476,)\n",
      "    predicted_test_classified_incorrect.shape: (1873476,)\n",
      "ic| TP_H + FN_H + FP_H + TN_H: 1873476\n",
      "    len(label_mask_current_deforestation_test): 54151420\n",
      "ic| TP_H + FN_H + FP_H + TN_H: 1873476\n",
      "    len(label_mask_current_deforestation_test): 54151420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88064436 0.95643761 0.67399831 0.03459699 0.59972329 0.35720172\n",
      " 0.097499  ]\n",
      "0.4260019229438447\n",
      "threshold 0.4260019229438447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| label_current_deforestation_test_classified_incorrect.shape: (1582183,)\n",
      "    predicted_test_classified_incorrect.shape: (1582183,)\n",
      "ic| TP_H + FN_H + FP_H + TN_H: 1582183\n",
      "    len(label_mask_current_deforestation_test): 54151420\n",
      "ic| TP_H + FN_H + FP_H + TN_H: 1582183\n",
      "    len(label_mask_current_deforestation_test): 54151420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86117235 0.9540806  0.71581434 0.02921776 0.57866578 0.25493879\n",
      " 0.10101944]\n",
      "0.4536937242602871\n",
      "threshold 0.4536937242602871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| label_current_deforestation_test_classified_incorrect.shape: (1413779,)\n",
      "    predicted_test_classified_incorrect.shape: (1413779,)\n",
      "ic| TP_H + FN_H + FP_H + TN_H: 1413779\n",
      "    len(label_mask_current_deforestation_test): 54151420\n",
      "ic| TP_H + FN_H + FP_H + TN_H: 1413779\n",
      "    len(label_mask_current_deforestation_test): 54151420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84968797 0.95203338 0.73800095 0.02610788 0.57074448 0.18450747\n",
      " 0.10266055]\n",
      "0.4192296986686353\n",
      "threshold 0.4192296986686353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| label_current_deforestation_test_classified_incorrect.shape: (1624191,)\n",
      "    predicted_test_classified_incorrect.shape: (1624191,)\n",
      "ic| TP_H + FN_H + FP_H + TN_H: 1624191\n",
      "    len(label_mask_current_deforestation_test): 54151420\n",
      "ic| TP_H + FN_H + FP_H + TN_H: 1624191\n",
      "    len(label_mask_current_deforestation_test): 54151420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86396395 0.95443704 0.70992239 0.02999351 0.58194102 0.27151545\n",
      " 0.10052133]\n",
      "0.4047019837390577\n",
      "threshold 0.4047019837390577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| label_current_deforestation_test_classified_incorrect.shape: (1716302,)\n",
      "    predicted_test_classified_incorrect.shape: (1716302,)\n",
      "ic| TP_H + FN_H + FP_H + TN_H: 1716302\n",
      "    len(label_mask_current_deforestation_test): 54151420\n",
      "ic| TP_H + FN_H + FP_H + TN_H: 1716302\n",
      "    len(label_mask_current_deforestation_test): 54151420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87008809 0.95520473 0.6963766  0.0316945  0.58989279 0.30669737\n",
      " 0.09945256]\n",
      "0.41732874489999916\n",
      "threshold 0.41732874489999916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| label_current_deforestation_test_classified_incorrect.shape: (1636054,)\n",
      "    predicted_test_classified_incorrect.shape: (1636054,)\n",
      "ic| TP_H + FN_H + FP_H + TN_H: 1636054\n",
      "    len(label_mask_current_deforestation_test): 54151420\n",
      "ic| TP_H + FN_H + FP_H + TN_H: 1636054\n",
      "    len(label_mask_current_deforestation_test): 54151420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86469211 0.95455054 0.70821081 0.03021258 0.58322579 0.27616815\n",
      " 0.1003618 ]\n",
      "0.4203878293371599\n",
      "threshold 0.4203878293371599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| label_current_deforestation_test_classified_incorrect.shape: (1616910,)\n",
      "    predicted_test_classified_incorrect.shape: (1616910,)\n",
      "ic| TP_H + FN_H + FP_H + TN_H: 1616910\n",
      "    len(label_mask_current_deforestation_test): 54151420\n",
      "ic| TP_H + FN_H + FP_H + TN_H: 1616910\n",
      "    len(label_mask_current_deforestation_test): 54151420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86344799 0.95436835 0.7109352  0.02985905 0.5815638  0.26873141\n",
      " 0.10059219]\n",
      "0.4190178102128489\n",
      "threshold 0.4190178102128489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| label_current_deforestation_test_classified_incorrect.shape: (1625543,)\n",
      "    predicted_test_classified_incorrect.shape: (1625543,)\n",
      "ic| TP_H + FN_H + FP_H + TN_H: 1625543\n",
      "    len(label_mask_current_deforestation_test): 54151420\n",
      "ic| TP_H + FN_H + FP_H + TN_H: 1625543\n",
      "    len(label_mask_current_deforestation_test): 54151420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8640499  0.95445687 0.70973342 0.03001847 0.5820589  0.27202643\n",
      " 0.10050641]\n",
      "0.4193481128107094\n",
      "threshold 0.4193481128107094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| label_current_deforestation_test_classified_incorrect.shape: (1623406,)\n",
      "    predicted_test_classified_incorrect.shape: (1623406,)\n",
      "ic| TP_H + FN_H + FP_H + TN_H: 1623406\n",
      "    len(label_mask_current_deforestation_test): 54151420\n",
      "ic| TP_H + FN_H + FP_H + TN_H: 1623406\n",
      "    len(label_mask_current_deforestation_test): 54151420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86391396 0.95442019 0.71001755 0.02997901 0.5819126  0.27126346\n",
      " 0.10052941]\n",
      "0.4191759345647506\n",
      "threshold 0.4191759345647506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| label_current_deforestation_test_classified_incorrect.shape: (1624523,)\n",
      "    predicted_test_classified_incorrect.shape: (1624523,)\n",
      "ic| TP_H + FN_H + FP_H + TN_H: 1624523\n",
      "    len(label_mask_current_deforestation_test): 54151420\n",
      "ic| TP_H + FN_H + FP_H + TN_H: 1624523\n",
      "    len(label_mask_current_deforestation_test): 54151420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86397872 0.95444451 0.70987345 0.02999964 0.58200625 0.27164594\n",
      " 0.10051604]\n",
      "0.4191425950140334\n",
      "threshold 0.4191425950140334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| label_current_deforestation_test_classified_incorrect.shape: (1624755,)\n",
      "    predicted_test_classified_incorrect.shape: (1624755,)\n",
      "ic| TP_H + FN_H + FP_H + TN_H: 1624755\n",
      "    len(label_mask_current_deforestation_test): 54151420\n",
      "ic| TP_H + FN_H + FP_H + TN_H: 1624755\n",
      "    len(label_mask_current_deforestation_test): 54151420\n",
      "ic| self.threshold_optimal: 0.4191759345647506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86399145 0.95444234 0.7098381  0.03000392 0.58204377 0.2717464\n",
      " 0.10051083]\n",
      "threshold:  0.4191759345647506\n",
      "threshold 0.4191759345647506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| label_current_deforestation_test_classified_incorrect.shape: (1624523,)\n",
      "    predicted_test_classified_incorrect.shape: (1624523,)\n",
      "ic| TP_H + FN_H + FP_H + TN_H: 1624523\n",
      "    len(label_mask_current_deforestation_test): 54151420\n",
      "ic| TP_H + FN_H + FP_H + TN_H: 1624523\n",
      "    len(label_mask_current_deforestation_test): 54151420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86397872 0.95444451 0.70987345 0.02999964 0.58200625 0.27164594\n",
      " 0.10051604]\n",
      "threshold 0.4191759345647506\n",
      "(54151420,) (54151420,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| self.m_optimal: {'AA': array([0.02999964]),\n",
      "                     'UEO': array([0.10051604]),\n",
      "                     'f1': 80.31,\n",
      "                     'f1_H': array([0.37040761]),\n",
      "                     'f1_L': array([0.90696129]),\n",
      "                     'precision_H': array([0.58200625]),\n",
      "                     'precision_L': array([0.86397872]),\n",
      "                     'recall_H': array([0.27164594]),\n",
      "                     'recall_L': array([0.95444451]),\n",
      "                     'recall_Ltotal': array([0.70987345])}\n",
      "ic| self.m_audited_optimal: {'f1': array([0.92990841]),\n",
      "                             'precision': array([0.89631513]),\n",
      "                             'recall': array([0.96611785])}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cm_audited [[53333633    82208]\n",
      " [   24923   710656]]\n",
      "[0.89631513 0.96611785]\n",
      "Result idx 0: {'uncertainty_result': {'metrics': {'precision_L': array([0.86397872]), 'recall_L': array([0.95444451]), 'recall_Ltotal': array([0.70987345]), 'AA': array([0.02999964]), 'precision_H': array([0.58200625]), 'recall_H': array([0.27164594]), 'UEO': array([0.10051604]), 'f1_L': array([0.90696129]), 'f1_H': array([0.37040761]), 'f1': 80.31}, 'metrics_audited': {'precision': array([0.89631513]), 'recall': array([0.96611785]), 'f1': array([0.92990841])}, 'exp': 8}}\n",
      "Grid execution idx: 0\n"
     ]
    }
   ],
   "source": [
    "if config['inferring'] == True:\n",
    "    idx = 0\n",
    "    results = []\n",
    "    error_count = 0\n",
    "\n",
    "    # while idx < len(repetition_n):\n",
    "    # for experiment_value, exp_id in zip(experiment_values, exp_ids):\n",
    "    for idx in range(repetition_n): # 10 repetitions\n",
    "\n",
    "\n",
    "        print(\"Beginning run number {}\".format(idx))\n",
    "        logger = Logger()\n",
    "        manager = manager_class(config, dataset, patchesHandler, logger)\n",
    "        print(\"manager.config\", manager.config)\n",
    "\n",
    "        manager.defineExperiment(exp) # fixed\n",
    "        manager.defineRepetitionId(idx) # varying from 0 to 10\n",
    "        manager.setExperimentPath()\n",
    "        manager.createLogFolders()\n",
    "\n",
    "        manager.loadDataset()\n",
    "\n",
    "        # %%\n",
    "        result = manager.run_predictor()\n",
    "        print(\"Result idx {}: {}\".format(idx, result))\n",
    "        results.append(result)\n",
    "\n",
    "\n",
    "        with open(manager.default_log_name, 'wb') as f:\n",
    "            pickle.dump(results, f)\n",
    "        print(\"Grid execution idx: {}\".format(idx))\n",
    "        # idx += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f07bf7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64080745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'uncertainty_result': {'metrics': {'precision_L': array([0.86397872]), 'recall_L': array([0.95444451]), 'recall_Ltotal': array([0.70987345]), 'AA': array([0.02999964]), 'precision_H': array([0.58200625]), 'recall_H': array([0.27164594]), 'UEO': array([0.10051604]), 'f1_L': array([0.90696129]), 'f1_H': array([0.37040761]), 'f1': 80.31}, 'metrics_audited': {'precision': array([0.89631513]), 'recall': array([0.96611785]), 'f1': array([0.92990841])}, 'exp': 8}}]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd4f4d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cc43863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uncertainty_result': {'metrics': {'precision_L': array([0.86397872]),\n",
       "   'recall_L': array([0.95444451]),\n",
       "   'recall_Ltotal': array([0.70987345]),\n",
       "   'AA': array([0.02999964]),\n",
       "   'precision_H': array([0.58200625]),\n",
       "   'recall_H': array([0.27164594]),\n",
       "   'UEO': array([0.10051604]),\n",
       "   'f1_L': array([0.90696129]),\n",
       "   'f1_H': array([0.37040761]),\n",
       "   'f1': 80.31},\n",
       "  'metrics_audited': {'precision': array([0.89631513]),\n",
       "   'recall': array([0.96611785]),\n",
       "   'f1': array([0.92990841])},\n",
       "  'exp': 8}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4819ba4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.31"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manager.f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13437081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.31\n"
     ]
    }
   ],
   "source": [
    "print(manager.f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "0593c6bd4eb743cc503a3c17025f83c5676f297db573750215a1bc8c88a990c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
