{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbd5b7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_v1 import *\n",
    "experiment_path = 'D:/jorg/phd/fifth_semester/project_forestcare/dataset_deforestation/experiments/'\n",
    "label_path = 'D:/jorg/phd/fifth_semester/project_forestcare/cloud_removal/dataset/Para_10m/'\n",
    "optical_im_path = 'D:/jorg/phd/fifth_semester/project_forestcare/dataset_deforestation/Para_2020/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64080745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask label shape:  \n",
      " (17730, 9203) \n",
      " Unique values:  \n",
      " [0. 1. 2.]\n"
     ]
    }
   ],
   "source": [
    "# Loading reference\n",
    "label_mask = np.load(label_path + 'mask_label_17730x9203.npy').astype('float32')\n",
    "print('Mask label shape: ', '\\n', label_mask.shape, '\\n', 'Unique values: ', '\\n', np.unique(label_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4819ba4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiles size:  3546 2300\n",
      "Mask size:  (17730, 9200)\n"
     ]
    }
   ],
   "source": [
    "# Creating tile mask\n",
    "grid_x, grid_y = 5,4\n",
    "mask_tiles = create_mask(label_mask.shape[0], label_mask.shape[1], grid_size=(grid_x, grid_y))\n",
    "label_mask = label_mask[:mask_tiles.shape[0], :mask_tiles.shape[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31bb7ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape:  (17730, 9203, 13)\n",
      "mask:  (17730, 9200)\n",
      "image stack:  (17730, 9200, 13)\n",
      "ref : (17730, 9200)\n"
     ]
    }
   ],
   "source": [
    "# Loading image stack\n",
    "image_stack = np.load(optical_im_path + 'optical_im.npy').astype('float32')\n",
    "print('Image shape: ', image_stack.shape)\n",
    "channels = image_stack.shape[-1]\n",
    "image_stack = image_stack[:mask_tiles.shape[0], :mask_tiles.shape[1],:]\n",
    "print('mask: ',mask_tiles.shape)\n",
    "print('image stack: ', image_stack.shape)\n",
    "print('ref :', label_mask.shape)\n",
    "#plt.imshow(mask_tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6c5f2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tiles:  [1, 3, 5, 8, 11, 13, 14, 20]\n",
      "Validation tiles:  [6, 19]\n",
      "Test tiles:  [2, 4, 7, 9, 10, 12, 15, 16, 17, 18]\n"
     ]
    }
   ],
   "source": [
    "# Defining tiles for training, validation and test sets\n",
    "tiles_tr = [1,3,5,8,11,13,14,20] \n",
    "tiles_val = [6,19]\n",
    "tiles_ts = list(set(np.arange(grid_x * grid_y)+1)-set(tiles_tr)-set(tiles_val))\n",
    "    \n",
    "print('Training tiles: ', tiles_tr)\n",
    "print('Validation tiles: ', tiles_val)\n",
    "print('Test tiles: ', tiles_ts)\n",
    "\n",
    "# Training and validation mask\n",
    "mask_tr_val = np.zeros((mask_tiles.shape)).astype('float32')\n",
    "\n",
    "for tr_ in tiles_tr:\n",
    "    mask_tr_val[mask_tiles == tr_] = 1\n",
    "\n",
    "for val_ in tiles_val:\n",
    "    mask_tr_val[mask_tiles == val_] = 2\n",
    "\n",
    "mask_amazon_ts = np.zeros((mask_tiles.shape)).astype('float32')\n",
    "for ts_ in tiles_ts:\n",
    "    mask_amazon_ts[mask_tiles == ts_] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45271c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting patches from the idx matrix\n",
    "overlap = 0.7\n",
    "patch_size = 128\n",
    "batch_size = 32\n",
    "im_idx = create_idx_image(label_mask)\n",
    "patches_idx = extract_patches(im_idx, patch_size=(patch_size, patch_size), overlap=overlap).reshape(-1,patch_size, patch_size)\n",
    "patches_mask = extract_patches(mask_tr_val, patch_size=(patch_size, patch_size), overlap=overlap).reshape(-1, patch_size, patch_size)\n",
    "del im_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f83b95b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training and validation patches:   41812 10260\n"
     ]
    }
   ],
   "source": [
    "# Selecting index trn val and test patches idx\n",
    "idx_trn = np.squeeze(np.where(patches_mask.sum(axis=(1, 2))==patch_size**2))\n",
    "idx_val = np.squeeze(np.where(patches_mask.sum(axis=(1, 2))==2*patch_size**2))\n",
    "del patches_mask\n",
    "\n",
    "patches_idx_trn = patches_idx[idx_trn]\n",
    "patches_idx_val = patches_idx[idx_val]\n",
    "del idx_trn, idx_val\n",
    "\n",
    "print('Number of training and validation patches:  ', len(patches_idx_trn), len(patches_idx_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76199f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training samples:  (3753, 128, 128) validation samples:  (1033, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "# Keeping patches with 2% of def class\n",
    "X_train = retrieve_idx_percentage(label_mask, patches_idx_trn, patch_size, pertentage = 0.2)\n",
    "X_valid = retrieve_idx_percentage(label_mask, patches_idx_val, patch_size, pertentage = 0.2)\n",
    "print('training samples: ', X_train.shape, 'validation samples: ', X_valid.shape)\n",
    "del patches_idx_trn, patches_idx_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9808000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating train and validation data generator\n",
    "train_datagen = ImageDataGenerator()\n",
    "valid_datagen = ImageDataGenerator()\n",
    "\n",
    "y_train = np.zeros((len(X_train)))\n",
    "y_valid = np.zeros((len(X_valid)))\n",
    "\n",
    "len_X_train = len(X_train)\n",
    "len_X_valid = len(X_valid)\n",
    "\n",
    "train_gen = train_datagen.flow(np.expand_dims(X_train, axis = -1), y_train,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True)\n",
    "\n",
    "valid_gen = valid_datagen.flow(np.expand_dims(X_valid, axis = -1), y_valid,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=False)\n",
    "\n",
    "del X_train, X_valid\n",
    "number_class = 3\n",
    "train_gen_batch = batch_generator(train_gen, image_stack, label_mask, patch_size, number_class)\n",
    "valid_gen_batch = batch_generator(valid_gen, image_stack, label_mask, patch_size, number_class)\n",
    "#del image_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "034a74fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating folder for the experiment\n",
    "exp = 0\n",
    "path_exp = experiment_path + 'exp' + str(exp)\n",
    "path_models = path_exp+'/models'\n",
    "path_maps = path_exp+'/pred_maps'\n",
    "\n",
    "if not os.path.exists(path_exp):\n",
    "    os.makedirs(path_exp)   \n",
    "if not os.path.exists(path_models):\n",
    "    os.makedirs(path_models)   \n",
    "if not os.path.exists(path_maps):\n",
    "    os.makedirs(path_maps)\n",
    "    \n",
    "times = 3\n",
    "method = 'resunet'\n",
    "nb_filters = [16, 32, 64, 128, 256]\n",
    "weights = [0.1, 0.9, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6630ce82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jchamorro\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_enc_net (InputLayer)      [(None, 128, 128, 13 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "res1_net1 (Conv2D)              (None, 128, 128, 16) 1888        input_enc_net[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "drop_net1 (Dropout)             (None, 128, 128, 16) 0           res1_net1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2_net1 (Conv2D)              (None, 128, 128, 16) 2320        drop_net1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res3_net1 (Conv2D)              (None, 128, 128, 16) 224         input_enc_net[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 128, 128, 16) 0           res2_net1[0][0]                  \n",
      "                                                                 res3_net1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool_net1 (MaxPooling2D)        (None, 64, 64, 16)   0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "res1_net2 (Conv2D)              (None, 64, 64, 32)   4640        pool_net1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "drop_net2 (Dropout)             (None, 64, 64, 32)   0           res1_net2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2_net2 (Conv2D)              (None, 64, 64, 32)   9248        drop_net2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res3_net2 (Conv2D)              (None, 64, 64, 32)   544         pool_net1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 64, 32)   0           res2_net2[0][0]                  \n",
      "                                                                 res3_net2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool_net2 (MaxPooling2D)        (None, 32, 32, 32)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res1_net3 (Conv2D)              (None, 32, 32, 64)   18496       pool_net2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "drop_net3 (Dropout)             (None, 32, 32, 64)   0           res1_net3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2_net3 (Conv2D)              (None, 32, 32, 64)   36928       drop_net3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res3_net3 (Conv2D)              (None, 32, 32, 64)   2112        pool_net2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 64)   0           res2_net3[0][0]                  \n",
      "                                                                 res3_net3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool_net3 (MaxPooling2D)        (None, 16, 16, 64)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res1_net4 (Conv2D)              (None, 16, 16, 64)   36928       pool_net3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "drop_net4 (Dropout)             (None, 16, 16, 64)   0           res1_net4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2_net4 (Conv2D)              (None, 16, 16, 64)   36928       drop_net4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res3_net4 (Conv2D)              (None, 16, 16, 64)   4160        pool_net3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 16, 16, 64)   0           res2_net4[0][0]                  \n",
      "                                                                 res3_net4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res1_net5 (Conv2D)              (None, 16, 16, 64)   36928       add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "drop_net5 (Dropout)             (None, 16, 16, 64)   0           res1_net5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2_net5 (Conv2D)              (None, 16, 16, 64)   36928       drop_net5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res3_net5 (Conv2D)              (None, 16, 16, 64)   4160        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 64)   0           res2_net5[0][0]                  \n",
      "                                                                 res3_net5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res1_net6 (Conv2D)              (None, 16, 16, 64)   36928       add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "drop_net6 (Dropout)             (None, 16, 16, 64)   0           res1_net6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2_net6 (Conv2D)              (None, 16, 16, 64)   36928       drop_net6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res3_net6 (Conv2D)              (None, 16, 16, 64)   4160        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 64)   0           res2_net6[0][0]                  \n",
      "                                                                 res3_net6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 32, 32, 64)   0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "upsampling_net3 (Conv2D)        (None, 32, 32, 64)   36928       up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate3 (Concatenate)      (None, 32, 32, 128)  0           add_2[0][0]                      \n",
      "                                                                 upsampling_net3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 128)  0           concatenate3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "upsampling_net2 (Conv2D)        (None, 64, 64, 32)   36896       up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate2 (Concatenate)      (None, 64, 64, 64)   0           add_1[0][0]                      \n",
      "                                                                 upsampling_net2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 64) 0           concatenate2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "upsampling_net1 (Conv2D)        (None, 128, 128, 16) 9232        up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate1 (Concatenate)      (None, 128, 128, 32) 0           add[0][0]                        \n",
      "                                                                 upsampling_net1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "output (Conv2D)                 (None, 128, 128, 3)  99          concatenate1[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 393,603\n",
      "Trainable params: 393,603\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jchamorro\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "351/351 [==============================] - 139s 341ms/step - loss: 0.1069 - accuracy: 0.7242 - val_loss: 0.1116 - val_accuracy: 0.7013\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11162, saving model to D:/jorg/phd/fifth_semester/project_forestcare/dataset_deforestation/experiments/exp0/models\\resunet_0.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jchamorro\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "351/351 [==============================] - 118s 337ms/step - loss: 0.0899 - accuracy: 0.7719 - val_loss: 0.1014 - val_accuracy: 0.7147\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.11162 to 0.10144, saving model to D:/jorg/phd/fifth_semester/project_forestcare/dataset_deforestation/experiments/exp0/models\\resunet_0.h5\n",
      "Epoch 3/100\n",
      "351/351 [==============================] - 95s 272ms/step - loss: 0.0849 - accuracy: 0.7790 - val_loss: 0.1019 - val_accuracy: 0.7324\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10144\n",
      "Epoch 4/100\n",
      "351/351 [==============================] - 99s 283ms/step - loss: 0.0807 - accuracy: 0.7864 - val_loss: 0.0972 - val_accuracy: 0.7489\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.10144 to 0.09720, saving model to D:/jorg/phd/fifth_semester/project_forestcare/dataset_deforestation/experiments/exp0/models\\resunet_0.h5\n",
      "Epoch 5/100\n",
      "351/351 [==============================] - 95s 270ms/step - loss: 0.0783 - accuracy: 0.7900 - val_loss: 0.0909 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.09720 to 0.09094, saving model to D:/jorg/phd/fifth_semester/project_forestcare/dataset_deforestation/experiments/exp0/models\\resunet_0.h5\n",
      "Epoch 6/100\n",
      "351/351 [==============================] - 92s 261ms/step - loss: 0.0769 - accuracy: 0.7946 - val_loss: 0.0997 - val_accuracy: 0.7447\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.09094\n",
      "Epoch 7/100\n",
      "351/351 [==============================] - 96s 274ms/step - loss: 0.0722 - accuracy: 0.8011 - val_loss: 0.1034 - val_accuracy: 0.7521\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.09094\n",
      "Epoch 8/100\n",
      "351/351 [==============================] - 99s 284ms/step - loss: 0.0720 - accuracy: 0.8025 - val_loss: 0.0918 - val_accuracy: 0.7475\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.09094\n",
      "Epoch 9/100\n",
      "351/351 [==============================] - 94s 268ms/step - loss: 0.0689 - accuracy: 0.8083 - val_loss: 0.1093 - val_accuracy: 0.7590\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.09094\n",
      "Epoch 10/100\n",
      "351/351 [==============================] - 92s 261ms/step - loss: 0.0676 - accuracy: 0.8101 - val_loss: 0.1117 - val_accuracy: 0.7421\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.09094\n",
      "Epoch 11/100\n",
      "351/351 [==============================] - 100s 284ms/step - loss: 0.0659 - accuracy: 0.8127 - val_loss: 0.1093 - val_accuracy: 0.7531\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.09094\n",
      "Epoch 12/100\n",
      "351/351 [==============================] - 98s 280ms/step - loss: 0.0635 - accuracy: 0.8177 - val_loss: 0.0989 - val_accuracy: 0.7624\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.09094\n",
      "Epoch 13/100\n",
      "351/351 [==============================] - 102s 290ms/step - loss: 0.0629 - accuracy: 0.8189 - val_loss: 0.1419 - val_accuracy: 0.7382\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.09094\n",
      "Epoch 14/100\n",
      "351/351 [==============================] - 101s 287ms/step - loss: 0.0610 - accuracy: 0.8232 - val_loss: 0.1068 - val_accuracy: 0.7559\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.09094\n",
      "Epoch 15/100\n",
      "351/351 [==============================] - 96s 274ms/step - loss: 0.0596 - accuracy: 0.8249 - val_loss: 0.1118 - val_accuracy: 0.7572\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.09094\n",
      "Epoch 00015: early stopping\n",
      "time:  1\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_enc_net (InputLayer)      [(None, 128, 128, 13 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "res1_net1 (Conv2D)              (None, 128, 128, 16) 1888        input_enc_net[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "drop_net1 (Dropout)             (None, 128, 128, 16) 0           res1_net1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2_net1 (Conv2D)              (None, 128, 128, 16) 2320        drop_net1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res3_net1 (Conv2D)              (None, 128, 128, 16) 224         input_enc_net[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 128, 128, 16) 0           res2_net1[0][0]                  \n",
      "                                                                 res3_net1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool_net1 (MaxPooling2D)        (None, 64, 64, 16)   0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res1_net2 (Conv2D)              (None, 64, 64, 32)   4640        pool_net1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "drop_net2 (Dropout)             (None, 64, 64, 32)   0           res1_net2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2_net2 (Conv2D)              (None, 64, 64, 32)   9248        drop_net2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res3_net2 (Conv2D)              (None, 64, 64, 32)   544         pool_net1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 64, 64, 32)   0           res2_net2[0][0]                  \n",
      "                                                                 res3_net2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool_net2 (MaxPooling2D)        (None, 32, 32, 32)   0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res1_net3 (Conv2D)              (None, 32, 32, 64)   18496       pool_net2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "drop_net3 (Dropout)             (None, 32, 32, 64)   0           res1_net3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2_net3 (Conv2D)              (None, 32, 32, 64)   36928       drop_net3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res3_net3 (Conv2D)              (None, 32, 32, 64)   2112        pool_net2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 32, 32, 64)   0           res2_net3[0][0]                  \n",
      "                                                                 res3_net3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool_net3 (MaxPooling2D)        (None, 16, 16, 64)   0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res1_net4 (Conv2D)              (None, 16, 16, 64)   36928       pool_net3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "drop_net4 (Dropout)             (None, 16, 16, 64)   0           res1_net4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2_net4 (Conv2D)              (None, 16, 16, 64)   36928       drop_net4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res3_net4 (Conv2D)              (None, 16, 16, 64)   4160        pool_net3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 16, 16, 64)   0           res2_net4[0][0]                  \n",
      "                                                                 res3_net4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res1_net5 (Conv2D)              (None, 16, 16, 64)   36928       add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "drop_net5 (Dropout)             (None, 16, 16, 64)   0           res1_net5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2_net5 (Conv2D)              (None, 16, 16, 64)   36928       drop_net5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res3_net5 (Conv2D)              (None, 16, 16, 64)   4160        add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 16, 16, 64)   0           res2_net5[0][0]                  \n",
      "                                                                 res3_net5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res1_net6 (Conv2D)              (None, 16, 16, 64)   36928       add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "drop_net6 (Dropout)             (None, 16, 16, 64)   0           res1_net6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2_net6 (Conv2D)              (None, 16, 16, 64)   36928       drop_net6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res3_net6 (Conv2D)              (None, 16, 16, 64)   4160        add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 16, 16, 64)   0           res2_net6[0][0]                  \n",
      "                                                                 res3_net6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 32, 32, 64)   0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "upsampling_net3 (Conv2D)        (None, 32, 32, 64)   36928       up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate3 (Concatenate)      (None, 32, 32, 128)  0           add_8[0][0]                      \n",
      "                                                                 upsampling_net3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 64, 64, 128)  0           concatenate3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "upsampling_net2 (Conv2D)        (None, 64, 64, 32)   36896       up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate2 (Concatenate)      (None, 64, 64, 64)   0           add_7[0][0]                      \n",
      "                                                                 upsampling_net2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 128, 128, 64) 0           concatenate2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "upsampling_net1 (Conv2D)        (None, 128, 128, 16) 9232        up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate1 (Concatenate)      (None, 128, 128, 32) 0           add_6[0][0]                      \n",
      "                                                                 upsampling_net1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "output (Conv2D)                 (None, 128, 128, 3)  99          concatenate1[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 393,603\n",
      "Trainable params: 393,603\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "351/351 [==============================] - 100s 273ms/step - loss: 0.1094 - accuracy: 0.7012 - val_loss: 0.1168 - val_accuracy: 0.7157\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11684, saving model to D:/jorg/phd/fifth_semester/project_forestcare/dataset_deforestation/experiments/exp0/models\\resunet_1.h5\n",
      "Epoch 2/100\n",
      "351/351 [==============================] - 95s 271ms/step - loss: 0.0921 - accuracy: 0.7692 - val_loss: 0.1089 - val_accuracy: 0.7278\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.11684 to 0.10894, saving model to D:/jorg/phd/fifth_semester/project_forestcare/dataset_deforestation/experiments/exp0/models\\resunet_1.h5\n",
      "Epoch 3/100\n",
      "351/351 [==============================] - 98s 280ms/step - loss: 0.0853 - accuracy: 0.7814 - val_loss: 0.1324 - val_accuracy: 0.7016\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10894\n",
      "Epoch 4/100\n",
      "351/351 [==============================] - 105s 299ms/step - loss: 0.0826 - accuracy: 0.7855 - val_loss: 0.1038 - val_accuracy: 0.7434\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.10894 to 0.10379, saving model to D:/jorg/phd/fifth_semester/project_forestcare/dataset_deforestation/experiments/exp0/models\\resunet_1.h5\n",
      "Epoch 5/100\n",
      "351/351 [==============================] - 107s 305ms/step - loss: 0.0788 - accuracy: 0.7903 - val_loss: 0.1136 - val_accuracy: 0.7356\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.10379\n",
      "Epoch 6/100\n",
      "351/351 [==============================] - 111s 317ms/step - loss: 0.0776 - accuracy: 0.7931 - val_loss: 0.1191 - val_accuracy: 0.7294\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.10379\n",
      "Epoch 7/100\n",
      "351/351 [==============================] - 117s 334ms/step - loss: 0.0748 - accuracy: 0.7966 - val_loss: 0.1202 - val_accuracy: 0.7208\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.10379\n",
      "Epoch 8/100\n",
      "351/351 [==============================] - 152s 432ms/step - loss: 0.0737 - accuracy: 0.7992 - val_loss: 0.1027 - val_accuracy: 0.7477\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.10379 to 0.10274, saving model to D:/jorg/phd/fifth_semester/project_forestcare/dataset_deforestation/experiments/exp0/models\\resunet_1.h5\n",
      "Epoch 9/100\n",
      "351/351 [==============================] - 116s 332ms/step - loss: 0.0712 - accuracy: 0.8030 - val_loss: 0.1010 - val_accuracy: 0.7578\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.10274 to 0.10102, saving model to D:/jorg/phd/fifth_semester/project_forestcare/dataset_deforestation/experiments/exp0/models\\resunet_1.h5\n",
      "Epoch 10/100\n",
      "351/351 [==============================] - 132s 376ms/step - loss: 0.0696 - accuracy: 0.8059 - val_loss: 0.1061 - val_accuracy: 0.7574\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.10102\n",
      "Epoch 11/100\n",
      "351/351 [==============================] - 144s 411ms/step - loss: 0.0671 - accuracy: 0.8106 - val_loss: 0.1190 - val_accuracy: 0.7441\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.10102\n",
      "Epoch 12/100\n",
      "351/351 [==============================] - 130s 372ms/step - loss: 0.0655 - accuracy: 0.8132 - val_loss: 0.1299 - val_accuracy: 0.7307\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.10102\n",
      "Epoch 13/100\n",
      "351/351 [==============================] - 125s 357ms/step - loss: 0.0628 - accuracy: 0.8174 - val_loss: 0.1249 - val_accuracy: 0.7340\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.10102\n",
      "Epoch 14/100\n",
      "351/351 [==============================] - 102s 291ms/step - loss: 0.0630 - accuracy: 0.8176 - val_loss: 0.1993 - val_accuracy: 0.7068\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.10102\n",
      "Epoch 15/100\n",
      "351/351 [==============================] - 123s 351ms/step - loss: 0.0610 - accuracy: 0.8216 - val_loss: 0.2359 - val_accuracy: 0.6908\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.10102\n",
      "Epoch 16/100\n",
      "351/351 [==============================] - 116s 331ms/step - loss: 0.0596 - accuracy: 0.8240 - val_loss: 0.1376 - val_accuracy: 0.7255\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.10102\n",
      "Epoch 17/100\n",
      "351/351 [==============================] - 110s 315ms/step - loss: 0.0590 - accuracy: 0.8255 - val_loss: 0.2011 - val_accuracy: 0.6943\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.10102\n",
      "Epoch 18/100\n",
      "351/351 [==============================] - 117s 334ms/step - loss: 0.0563 - accuracy: 0.8299 - val_loss: 0.2163 - val_accuracy: 0.6881\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.10102\n",
      "Epoch 19/100\n",
      "351/351 [==============================] - 109s 312ms/step - loss: 0.0554 - accuracy: 0.8315 - val_loss: 0.1776 - val_accuracy: 0.7097\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.10102\n",
      "Epoch 00019: early stopping\n",
      "time:  2\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_enc_net (InputLayer)      [(None, 128, 128, 13 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "res1_net1 (Conv2D)              (None, 128, 128, 16) 1888        input_enc_net[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "drop_net1 (Dropout)             (None, 128, 128, 16) 0           res1_net1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2_net1 (Conv2D)              (None, 128, 128, 16) 2320        drop_net1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res3_net1 (Conv2D)              (None, 128, 128, 16) 224         input_enc_net[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 128, 128, 16) 0           res2_net1[0][0]                  \n",
      "                                                                 res3_net1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool_net1 (MaxPooling2D)        (None, 64, 64, 16)   0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res1_net2 (Conv2D)              (None, 64, 64, 32)   4640        pool_net1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "drop_net2 (Dropout)             (None, 64, 64, 32)   0           res1_net2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2_net2 (Conv2D)              (None, 64, 64, 32)   9248        drop_net2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res3_net2 (Conv2D)              (None, 64, 64, 32)   544         pool_net1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 64, 64, 32)   0           res2_net2[0][0]                  \n",
      "                                                                 res3_net2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool_net2 (MaxPooling2D)        (None, 32, 32, 32)   0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res1_net3 (Conv2D)              (None, 32, 32, 64)   18496       pool_net2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "drop_net3 (Dropout)             (None, 32, 32, 64)   0           res1_net3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2_net3 (Conv2D)              (None, 32, 32, 64)   36928       drop_net3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res3_net3 (Conv2D)              (None, 32, 32, 64)   2112        pool_net2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 32, 32, 64)   0           res2_net3[0][0]                  \n",
      "                                                                 res3_net3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool_net3 (MaxPooling2D)        (None, 16, 16, 64)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res1_net4 (Conv2D)              (None, 16, 16, 64)   36928       pool_net3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "drop_net4 (Dropout)             (None, 16, 16, 64)   0           res1_net4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2_net4 (Conv2D)              (None, 16, 16, 64)   36928       drop_net4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res3_net4 (Conv2D)              (None, 16, 16, 64)   4160        pool_net3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 16, 16, 64)   0           res2_net4[0][0]                  \n",
      "                                                                 res3_net4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res1_net5 (Conv2D)              (None, 16, 16, 64)   36928       add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "drop_net5 (Dropout)             (None, 16, 16, 64)   0           res1_net5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2_net5 (Conv2D)              (None, 16, 16, 64)   36928       drop_net5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res3_net5 (Conv2D)              (None, 16, 16, 64)   4160        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 16, 16, 64)   0           res2_net5[0][0]                  \n",
      "                                                                 res3_net5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res1_net6 (Conv2D)              (None, 16, 16, 64)   36928       add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "drop_net6 (Dropout)             (None, 16, 16, 64)   0           res1_net6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2_net6 (Conv2D)              (None, 16, 16, 64)   36928       drop_net6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res3_net6 (Conv2D)              (None, 16, 16, 64)   4160        add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 16, 16, 64)   0           res2_net6[0][0]                  \n",
      "                                                                 res3_net6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)  (None, 32, 32, 64)   0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "upsampling_net3 (Conv2D)        (None, 32, 32, 64)   36928       up_sampling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate3 (Concatenate)      (None, 32, 32, 128)  0           add_14[0][0]                     \n",
      "                                                                 upsampling_net3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2D)  (None, 64, 64, 128)  0           concatenate3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "upsampling_net2 (Conv2D)        (None, 64, 64, 32)   36896       up_sampling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate2 (Concatenate)      (None, 64, 64, 64)   0           add_13[0][0]                     \n",
      "                                                                 upsampling_net2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2D)  (None, 128, 128, 64) 0           concatenate2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "upsampling_net1 (Conv2D)        (None, 128, 128, 16) 9232        up_sampling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate1 (Concatenate)      (None, 128, 128, 32) 0           add_12[0][0]                     \n",
      "                                                                 upsampling_net1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "output (Conv2D)                 (None, 128, 128, 3)  99          concatenate1[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 393,603\n",
      "Trainable params: 393,603\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "351/351 [==============================] - 129s 347ms/step - loss: 0.1074 - accuracy: 0.6996 - val_loss: 0.1010 - val_accuracy: 0.7319\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10099, saving model to D:/jorg/phd/fifth_semester/project_forestcare/dataset_deforestation/experiments/exp0/models\\resunet_2.h5\n",
      "Epoch 2/100\n",
      "351/351 [==============================] - 106s 301ms/step - loss: 0.0913 - accuracy: 0.7696 - val_loss: 0.0966 - val_accuracy: 0.7510\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.10099 to 0.09663, saving model to D:/jorg/phd/fifth_semester/project_forestcare/dataset_deforestation/experiments/exp0/models\\resunet_2.h5\n",
      "Epoch 3/100\n",
      "351/351 [==============================] - 101s 288ms/step - loss: 0.0857 - accuracy: 0.7793 - val_loss: 0.0912 - val_accuracy: 0.7696\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.09663 to 0.09121, saving model to D:/jorg/phd/fifth_semester/project_forestcare/dataset_deforestation/experiments/exp0/models\\resunet_2.h5\n",
      "Epoch 4/100\n",
      "351/351 [==============================] - 99s 281ms/step - loss: 0.0825 - accuracy: 0.7862 - val_loss: 0.0979 - val_accuracy: 0.7617\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.09121\n",
      "Epoch 5/100\n",
      "351/351 [==============================] - 105s 299ms/step - loss: 0.0793 - accuracy: 0.7920 - val_loss: 0.1103 - val_accuracy: 0.7461\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.09121\n",
      "Epoch 6/100\n",
      "351/351 [==============================] - 105s 298ms/step - loss: 0.0765 - accuracy: 0.7966 - val_loss: 0.1057 - val_accuracy: 0.7574\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.09121\n",
      "Epoch 7/100\n",
      "351/351 [==============================] - 115s 328ms/step - loss: 0.0749 - accuracy: 0.7991 - val_loss: 0.1220 - val_accuracy: 0.7415\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.09121\n",
      "Epoch 8/100\n",
      "351/351 [==============================] - 101s 287ms/step - loss: 0.0728 - accuracy: 0.8030 - val_loss: 0.1143 - val_accuracy: 0.7570\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.09121\n",
      "Epoch 9/100\n",
      "351/351 [==============================] - 96s 273ms/step - loss: 0.0697 - accuracy: 0.8079 - val_loss: 0.1292 - val_accuracy: 0.7514\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.09121\n",
      "Epoch 10/100\n",
      "351/351 [==============================] - 104s 296ms/step - loss: 0.0680 - accuracy: 0.8101 - val_loss: 0.1354 - val_accuracy: 0.7366\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.09121\n",
      "Epoch 11/100\n",
      "351/351 [==============================] - 106s 302ms/step - loss: 0.0663 - accuracy: 0.8132 - val_loss: 0.1334 - val_accuracy: 0.7503\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.09121\n",
      "Epoch 12/100\n",
      "351/351 [==============================] - 114s 325ms/step - loss: 0.0641 - accuracy: 0.8165 - val_loss: 0.1610 - val_accuracy: 0.7234\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.09121\n",
      "Epoch 13/100\n",
      "351/351 [==============================] - 109s 312ms/step - loss: 0.0632 - accuracy: 0.8185 - val_loss: 0.1501 - val_accuracy: 0.7309\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.09121\n",
      "Epoch 00013: early stopping\n"
     ]
    }
   ],
   "source": [
    "metrics_all = []\n",
    "training = False\n",
    "if training == True:\n",
    "    for tm in range(0,times):\n",
    "        print('time: ', tm)\n",
    "\n",
    "        rows = patch_size\n",
    "        cols = patch_size\n",
    "        adam = Adam(lr = 1e-3 , beta_1=0.9)\n",
    "        \n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        input_shape = (rows, cols, channels)\n",
    "        model = build_resunet(input_shape, nb_filters, number_class)\n",
    "        \n",
    "        model.compile(optimizer=adam, loss=loss, metrics=['accuracy'])\n",
    "        model.summary()\n",
    "\n",
    "        earlystop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=10, verbose=1, mode='min')\n",
    "        checkpoint = ModelCheckpoint(path_models+ '/' + method +'_'+str(tm)+'.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "        lr_reduce = ReduceLROnPlateau(factor=0.9, min_delta=0.0001, patience=5, verbose=1)\n",
    "        callbacks_list = [earlystop, checkpoint]\n",
    "        # train the model\n",
    "        start_training = time.time()\n",
    "        history = model.fit_generator(train_gen_batch,\n",
    "                                steps_per_epoch=len_X_train*3//train_gen.batch_size,\n",
    "                                validation_data=valid_gen_batch,\n",
    "                                validation_steps=len_X_valid*3//valid_gen.batch_size,\n",
    "                                epochs=100,\n",
    "                                callbacks=callbacks_list)\n",
    "        end_training = time.time() - start_training\n",
    "        metrics_all.append(end_training)\n",
    "        del model, history\n",
    "\n",
    "    # Saving training time\n",
    "    np.save(path_exp+'/metrics_tr.npy', metrics_all)\n",
    "    del train_gen_batch, valid_gen_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e741522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-30.0 -16.0\n",
      "time:  0\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[1,64,3552,2304] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_3/upsampling_net1/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_predict_function_57112]\n\nFunction call stack:\npredict_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\JCHAMO~1\\AppData\\Local\\Temp/ipykernel_1516/1959846443.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_patches_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mpatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage1_pad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpatch_size_rows\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mpatch_size_rows\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatch_size_cols\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mpatch_size_cols\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[0mpredictions_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mpatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[0mpatch_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1725\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1726\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1727\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1728\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1729\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    954\u001b[0m               *args, **kwds)\n\u001b[0;32m    955\u001b[0m       \u001b[1;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 956\u001b[1;33m       return self._concrete_stateful_fn._call_flat(\n\u001b[0m\u001b[0;32m    957\u001b[0m           filtered_flat_args, self._concrete_stateful_fn.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m    958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[1,64,3552,2304] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_3/upsampling_net1/Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_predict_function_57112]\n\nFunction call stack:\npredict_function\n"
     ]
    }
   ],
   "source": [
    "#%% Test loop\n",
    "metrics_ts = []\n",
    "n_pool = 3\n",
    "n_rows = 5\n",
    "n_cols = 4\n",
    "rows, cols = image_stack.shape[:2]\n",
    "pad_rows = rows - np.ceil(rows/(n_rows*2**n_pool))*n_rows*2**n_pool\n",
    "pad_cols = cols - np.ceil(cols/(n_cols*2**n_pool))*n_cols*2**n_pool\n",
    "print(pad_rows, pad_cols)\n",
    "\n",
    "npad = ((0, int(abs(pad_rows))), (0, int(abs(pad_cols))), (0, 0))\n",
    "image1_pad = np.pad(image_stack, pad_width=npad, mode='reflect')\n",
    "del image_stack\n",
    "\n",
    "h, w, c = image1_pad.shape\n",
    "patch_size_rows = h//n_rows\n",
    "patch_size_cols = w//n_cols\n",
    "num_patches_x = int(h/patch_size_rows)\n",
    "num_patches_y = int(w/patch_size_cols)\n",
    "\n",
    "new_model = build_resunet(input_shape=(patch_size_rows,patch_size_cols, c), nb_filters = nb_filters, n_classes=3)\n",
    "\n",
    "metrics_all =[]\n",
    "\n",
    "for tm in range(0,times):\n",
    "    print('time: ', tm)\n",
    "    model = load_model(path_models+ '/' + method +'_'+str(tm)+'.h5', compile=False)\n",
    "    \n",
    "    for l in range(1, len(model.layers)):\n",
    "        new_model.layers[l].set_weights(model.layers[l].get_weights())\n",
    "    \n",
    "    start_test = time.time()\n",
    "    patch_t = []\n",
    "    \n",
    "    for i in range(0,num_patches_y):\n",
    "        for j in range(0,num_patches_x):\n",
    "            patch = image1_pad[patch_size_rows*j:patch_size_rows*(j+1), patch_size_cols*i:patch_size_cols*(i+1), :]\n",
    "            predictions_ = new_model.predict(np.expand_dims(patch, axis=0))\n",
    "            del patch \n",
    "            patch_t.append(predictions_[:,:,:,1])\n",
    "            del predictions_\n",
    "    ts_time =  time.time() - start_test\n",
    "    patches_pred = np.asarray(patch_t).astype(np.float32)\n",
    "    # Recinstructing predicted map\n",
    "    prob_recontructed = pred_reconctruct(h, w, num_patches_x, num_patches_y, patch_size_rows, patch_size_cols, patches_pred)\n",
    "    np.save(path_maps+'/'+'prob_'+str(tm)+'.npy',prob_recontructed) \n",
    "\n",
    "    metrics_all.append(ts_time)\n",
    "    del prob_recontructed, model, patches_pred\n",
    "metrics_ = np.asarray(metrics_all)\n",
    "del image1_pad\n",
    "# Saving test time\n",
    "np.save(path_exp+'/metrics_ts.npy', metrics_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc025ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_rec = np.zeros((h, w, times))\n",
    "\n",
    "for tm in range (0, times):\n",
    "    print(tm)\n",
    "    prob_rec[:,:,tm] = np.load(path_maps+'/'+'prob_'+str(tm)+'.npy').astype(np.float32)\n",
    "\n",
    "mean_prob = np.mean(prob_rec, axis = -1)\n",
    "np.save(path_maps+'/prob_mean.npy', mean_prob)\n",
    "\n",
    "fig1 = plt.figure(figsize=(10,10))\n",
    "plt.imshow(mean_prob, cmap = 'jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1316e0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing metrics over the test tiles\n",
    "mean_prob = mean_prob[:label_mask.shape[0], :label_mask.shape[1]]\n",
    "ref1 = np.ones_like(label_mask).astype(np.float32)\n",
    "\n",
    "ref1 [label_mask == 2] = 0\n",
    "TileMask = mask_amazon_ts * ref1\n",
    "GTTruePositives = label_mask==1\n",
    "\n",
    "# Metrics for th=0.5    \n",
    "ProbList_05 = [0.5]\n",
    "\n",
    "metrics_05 = matrics_AA_recall(ProbList_05, mean_prob, label_mask, mask_amazon_ts, 625)\n",
    "print('Metrics th = 0.5: ', metrics_05*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0791592",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
